# NIST Statistical Test Suite (STS) Testing

## Overview

This document describes how to run and interpret NIST Statistical Test Suite (STS) tests for validating the cryptographic randomness of the key generators in this repository.

The NIST STS is a comprehensive battery of statistical tests designed to evaluate the randomness of binary sequences generated by cryptographic random number generators (RNGs). These tests are based on **NIST Special Publication 800-22 Rev. 1a**.

## Table of Contents

1. [Background](#background)
2. [Quick Start](#quick-start)
3. [Local Testing](#local-testing)
4. [CI/CD Integration](#cicd-integration)
5. [Understanding Results](#understanding-results)
6. [Test Descriptions](#test-descriptions)
7. [Troubleshooting](#troubleshooting)
8. [Advanced Usage](#advanced-usage)

## Background

### What is NIST STS?

The NIST Statistical Test Suite is a collection of 15 statistical tests developed by the National Institute of Standards and Technology (NIST) to evaluate the randomness of binary sequences. These tests are essential for:

- **Cryptographic Validation**: Ensuring random number generators produce statistically random output
- **Security Compliance**: Meeting regulatory requirements for cryptographic systems
- **Quality Assurance**: Detecting biases or patterns in generated sequences

### Why Test Randomness?

Cryptographic security relies on unpredictable random numbers. Poor randomness can lead to:
- Predictable keys that can be guessed by attackers
- Reduced security margins in cryptographic protocols
- Vulnerable systems that appear secure but aren't

### Our Implementation

This repository includes:
1. **Python-based NIST STS implementation** - 7 core tests from NIST SP 800-22
2. **Automated test scripts** - Generate and test binary sequences
3. **CI/CD integration** - Automatic testing on every push/PR
4. **Multiple generators tested**:
   - Universal QKD (GCP-1)
   - GQS-1 Test Vectors
   - CRYSTALS-Kyber (NIST PQC)
   - CRYSTALS-Dilithium (NIST PQC)
   - SPHINCS+ (NIST PQC)

## Quick Start

### Prerequisites

```bash
# Ensure the package is installed
pip install -e .

# Verify installation
python -c "from gq import generate_universal_keys; print('✓ Package installed')"
```

### Running Tests (Simple)

```bash
# Generate 1 million bits and test
python scripts/generate_nist_binary.py -n 1000000 -o data/random.txt
python scripts/run_nist_tests.py -i data/random.txt
```

### Expected Output

```
Running NIST Statistical Test Suite on 1,000,000 bits...
======================================================================
✓ Frequency (Monobit)..................... p=0.767230 [PASS]
✓ Block Frequency......................... p=0.314466 [PASS]
✓ Runs.................................... p=0.782615 [PASS]
✓ Longest Run of Ones..................... p=0.102612 [PASS]
✓ Serial (m=2)............................ p=0.338046 [PASS]
✓ Approximate Entropy (m=2)............... p=0.102460 [PASS]
✓ Cumulative Sums......................... p=0.109599 [PASS]
======================================================================

Results: 7/7 tests passed (100.0%)
✓ NIST Statistical Test Suite: PASSED
```

## Local Testing

### Step 1: Generate Binary Data

The first step is to generate binary random data from one of the cryptographic generators:

```bash
# Universal QKD (default) - 1 million bits
python scripts/generate_nist_binary.py -n 1000000 -o data/universal.txt

# GQS-1 Test Vectors - 10 million bits
python scripts/generate_nist_binary.py -n 10000000 -t gqs1 -o data/gqs1.txt

# Kyber PQC - 1 million bits
python scripts/generate_nist_binary.py -n 1000000 -t kyber -o data/kyber.txt

# Dilithium PQC - 1 million bits
python scripts/generate_nist_binary.py -n 1000000 -t dilithium -o data/dilithium.txt

# SPHINCS+ PQC - 1 million bits
python scripts/generate_nist_binary.py -n 1000000 -t sphincs -o data/sphincs.txt
```

**Generator Types:**
- `universal` - Universal QKD (GCP-1) keys [16 bytes per key]
- `gqs1` - GQS-1 test vectors [16 bytes per vector]
- `kyber` - Kyber-768 PQC seeds [32 bytes per seed]
- `dilithium` - Dilithium3 PQC seeds [32 bytes per seed]
- `sphincs` - SPHINCS+-192f PQC seeds [64 bytes per seed]

**Important Notes:**
- Minimum recommended: 100,000 bits (for meaningful results)
- Standard test size: 1,000,000 bits
- Extended testing: 10,000,000+ bits
- Output format: ASCII text file with '0' and '1' characters

### Step 2: Run NIST Tests

```bash
# Basic test run
python scripts/run_nist_tests.py -i data/universal.txt

# Save results to JSON
python scripts/run_nist_tests.py -i data/universal.txt -o results/universal_results.json

# Custom significance level (default is 0.01)
python scripts/run_nist_tests.py -i data/universal.txt --alpha 0.01
```

### Step 3: Review Results

The test runner outputs:
1. **Console output** - Real-time test results
2. **JSON file** (optional) - Detailed results for further analysis
3. **Exit code** - 0 for pass, 1 for fail

Example JSON output:
```json
{
  "metadata": {
    "total_bits": 1000000,
    "significance_level": 0.01,
    "timestamp": "2026-01-05T05:30:00"
  },
  "tests": {
    "Frequency (Monobit)": {
      "p_value": 0.767230,
      "passed": true,
      "status": "PASS"
    },
    ...
  },
  "summary": {
    "total_tests": 7,
    "passed": 7,
    "failed": 0,
    "pass_rate": 1.0,
    "overall_passed": true
  }
}
```

## CI/CD Integration

### Automated Testing

The repository includes integration tests that verify the NIST STS workflow:

```bash
# Run integration tests locally
python -m unittest test_nist_sts_integration -v

# Or as part of the full test suite
python -m unittest discover
```

These tests verify:
- Scripts exist and are executable
- Binary data generation works for all generators
- NIST tests run successfully
- Results have correct JSON structure

### GitHub Actions Workflow

The repository includes a GitHub Actions workflow (`.github/workflows/nist-sts.yml`) that:

1. **Automatically runs** on push/PR to main, develop, or claude/** branches
2. **Tests multiple generators** - Universal QKD, Kyber, Dilithium, SPHINCS+
3. **Saves artifacts** - Test results and binary data for 30 days
4. **Validates results** - Fails the build if tests don't pass
5. **Generates summary** - Displays results in GitHub Actions summary

### Workflow Jobs

```yaml
Jobs:
  - nist-sts-universal    # Tests Universal QKD generator
  - nist-sts-pqc          # Tests PQC generators (matrix: kyber, dilithium, sphincs)
  - nist-sts-validation   # Validates all results and fails if any fail
```

### Triggering Manual Runs

You can manually trigger the workflow with custom parameters:

1. Go to **Actions** → **NIST Statistical Test Suite**
2. Click **Run workflow**
3. (Optional) Set custom number of bits (default: 1,000,000)
4. Click **Run workflow**

### Viewing Results

1. Navigate to the **Actions** tab in GitHub
2. Click on the workflow run
3. View the **Summary** for test results
4. Download **Artifacts** for detailed JSON results and binary data

## Understanding Results

### P-Values

Each statistical test produces a **p-value** between 0 and 1:

- **P-value ≥ 0.01**: Test PASSED (sequence appears random)
- **P-value < 0.01**: Test FAILED (sequence may not be random)

The significance level (α = 0.01) means:
- We expect 1% of tests to fail by chance even for truly random data
- With 7 tests, it's acceptable for 0-1 tests to fail occasionally
- If 2+ tests consistently fail, there may be a real problem

### Interpretation Guidelines

| Pass Rate | Interpretation |
|-----------|----------------|
| 100% (7/7) | Excellent - All tests passed |
| 86-99% (6/7) | Good - Within acceptable range |
| 71-85% (5/7) | Marginal - May indicate minor issues |
| < 71% (<5/7) | Failed - Indicates significant randomness problems |

**Note:** The test suite uses an **85% threshold** (6/7 tests) to account for statistical variation.

### Common Failure Scenarios

1. **Single test fails** - Usually acceptable, may be statistical chance
2. **Same test consistently fails** - Indicates specific pattern in data
3. **Multiple tests fail** - Serious randomness problem
4. **All tests fail** - Generator is completely broken

### What to Do if Tests Fail

1. **Run again** - Single failures may be statistical flukes
2. **Increase sample size** - Test with 10M+ bits for more reliable results
3. **Check specific test** - Different tests detect different types of bias
4. **Review generator code** - Look for bugs or implementation issues
5. **Compare with baseline** - Test known-good data for sanity check

## Test Descriptions

### 1. Frequency (Monobit) Test

**Purpose**: Tests if the number of ones and zeros are approximately equal.

**What it detects**: 
- Biased generator that produces too many 0s or 1s
- Basic sanity check for randomness

**Pass criteria**: P-value ≥ 0.01

### 2. Block Frequency Test

**Purpose**: Tests if the proportion of ones is approximately 0.5 within blocks.

**What it detects**:
- Local biases within subsequences
- Patterns that appear in specific block sizes

**Block size**: 128 bits (default)

### 3. Runs Test

**Purpose**: Tests the total number of runs (uninterrupted sequences of identical bits).

**What it detects**:
- Too many or too few transitions between 0 and 1
- Clustering of similar bits

**Example**: `0011100` has 3 runs: `00`, `111`, `00`

### 4. Longest Run of Ones Test

**Purpose**: Tests the longest run of ones within blocks.

**What it detects**:
- Unusual patterns of consecutive ones
- Non-uniformity in run lengths

### 5. Serial Test

**Purpose**: Tests the frequency of all possible overlapping m-bit patterns.

**What it detects**:
- Bias in specific bit patterns
- Non-uniform distribution of 2-bit sequences

**Pattern size**: 2 bits (tests 00, 01, 10, 11)

### 6. Approximate Entropy Test

**Purpose**: Compares frequency of overlapping blocks of two consecutive lengths.

**What it detects**:
- Patterns in overlapping sequences
- Deviation from expected entropy

### 7. Cumulative Sums Test

**Purpose**: Tests the maximum excursion of the cumulative sum from zero.

**What it detects**:
- Trends or biases in the sequence
- Gradual drift from randomness

## Troubleshooting

### Issue: "Module not found" error

**Solution:**
```bash
# Make sure the package is installed
pip install -e .

# Verify installation
python -c "from gq import generate_universal_keys; print('OK')"
```

### Issue: Tests consistently fail for a specific generator

**Possible causes:**
1. Bug in the generator implementation
2. Insufficient entropy in the seed
3. Improper configuration parameters

**Debug steps:**
```bash
# 1. Test with known-good generator first
python scripts/generate_nist_binary.py -n 1000000 -t universal -o data/test.txt
python scripts/run_nist_tests.py -i data/test.txt

# 2. Increase sample size
python scripts/generate_nist_binary.py -n 10000000 -t <generator> -o data/test.txt
python scripts/run_nist_tests.py -i data/test.txt

# 3. Check basic statistics
python scripts/generate_nist_binary.py -n 1000000 -t <generator> -o data/test.txt
# Look at the "Basic Statistics" output
```

### Issue: P-values are suspiciously high (all close to 1.0)

**Possible cause:** Not enough data or implementation issue

**Solution:**
```bash
# Generate more data
python scripts/generate_nist_binary.py -n 10000000 -o data/test.txt

# Review the test implementation
# P-values should be distributed across [0, 1]
```

### Issue: File size is too large

**Solution:**
```bash
# Use fewer bits for quick tests
python scripts/generate_nist_binary.py -n 100000 -o data/test.txt

# Or compress the results
gzip results/*.json
```

### Issue: Tests take too long

**Causes:**
- Large sample size (10M+ bits)
- Slow generator
- Complex statistical calculations

**Solutions:**
```bash
# 1. Use smaller sample for quick validation
python scripts/generate_nist_binary.py -n 100000 -o data/test.txt

# 2. Pre-generate data files for repeated testing
python scripts/generate_nist_binary.py -n 1000000 -o data/cached.txt
# Then run tests multiple times on same data
python scripts/run_nist_tests.py -i data/cached.txt
```

### Issue: CI/CD workflow fails

**Common causes:**
1. Generator produces biased output
2. Changes broke the generator
3. Insufficient system resources

**Debug steps:**
1. Check the GitHub Actions logs for specific test failures
2. Download artifacts to review detailed results
3. Reproduce locally with same parameters
4. Compare with previous successful runs

## Advanced Usage

### Testing Custom Generators

To test your own random number generator:

1. Generate binary output as ASCII '0' and '1' characters:
```python
# your_generator.py
def my_generator():
    # Your implementation here
    pass

# Generate and save
with open('data/custom.txt', 'w') as f:
    for i in range(1000000):
        bit = my_generator()
        f.write('1' if bit else '0')
```

2. Run tests:
```bash
python scripts/run_nist_tests.py -i data/custom.txt
```

### Batch Testing

Test multiple generators at once:

```bash
#!/bin/bash
# test_all.sh

GENERATORS="universal gqs1 kyber dilithium sphincs"
BITS=1000000

for gen in $GENERATORS; do
    echo "Testing $gen..."
    python scripts/generate_nist_binary.py -n $BITS -t $gen -o data/${gen}.txt
    python scripts/run_nist_tests.py -i data/${gen}.txt -o results/${gen}_results.json
done

echo "All tests complete!"
```

### Custom Significance Levels

Adjust the significance level for more or less stringent testing:

```bash
# Very strict (α = 0.001) - fewer false positives
python scripts/run_nist_tests.py -i data/random.txt --alpha 0.001

# Standard (α = 0.01) - recommended
python scripts/run_nist_tests.py -i data/random.txt --alpha 0.01

# Lenient (α = 0.05) - more false positives
python scripts/run_nist_tests.py -i data/random.txt --alpha 0.05
```

### Large-Scale Testing

For comprehensive validation:

```bash
# Generate 10 million bits (takes longer but more reliable)
python scripts/generate_nist_binary.py -n 10000000 -o data/large.txt

# Run tests
python scripts/run_nist_tests.py -i data/large.txt -o results/large_results.json

# Analyze results
python -c "
import json
with open('results/large_results.json') as f:
    r = json.load(f)
    
for test, result in r['tests'].items():
    print(f\"{test}: {result['p_value']:.6f} - {result['status']}\")
"
```

### Comparing Generators

```bash
# Test multiple generators and compare
for gen in universal gqs1 kyber dilithium sphincs; do
    python scripts/generate_nist_binary.py -n 1000000 -t $gen -o data/${gen}.txt
    python scripts/run_nist_tests.py -i data/${gen}.txt -o results/${gen}.json
done

# Compare pass rates
python -c "
import json
import glob

for file in glob.glob('results/*.json'):
    with open(file) as f:
        r = json.load(f)
        name = file.split('/')[-1].split('.')[0]
        passed = r['summary']['passed']
        total = r['summary']['total_tests']
        print(f'{name}: {passed}/{total} ({passed/total*100:.0f}%)')
"
```

## References

- [NIST SP 800-22 Rev. 1a](https://csrc.nist.gov/publications/detail/sp/800-22/rev-1a/final) - Statistical Test Suite for Random Number Generators
- [NIST Random Bit Generation](https://csrc.nist.gov/projects/random-bit-generation) - Documentation and software
- [NIST FIPS 203](https://csrc.nist.gov/pubs/fips/203/final) - ML-KEM (Kyber)
- [NIST FIPS 204](https://csrc.nist.gov/pubs/fips/204/final) - ML-DSA (Dilithium)
- [NIST FIPS 205](https://csrc.nist.gov/pubs/fips/205/final) - SLH-DSA (SPHINCS+)

## Support

For issues or questions:
1. Check the [troubleshooting section](#troubleshooting)
2. Review GitHub Actions logs for CI/CD issues
3. Open an issue on GitHub with:
   - Command used
   - Full error output
   - Test results (if available)
   - System information (OS, Python version)

## License

This testing infrastructure is part of the golden-quantum package and follows the same GPL-3.0-or-later license.
